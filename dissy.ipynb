{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1_avgn-aBGMXGtPD7MRZBkiQvN9Z7K8MY",
      "authorship_tag": "ABX9TyNBICnRimMIodms/b9BQ2Xc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AloraTab/aat2000/blob/main/dissy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "18ye21aUJuyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas==1.5.3\n",
        "%pip install tensorflow-addons==0.19.0\n"
      ],
      "metadata": {
        "id": "igoiIt__W5xU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c796ee8-d12f-43bf-c265-c9aadcac2a2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.3) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.4.4\n",
            "    Uninstalling pandas-1.4.4:\n",
            "      Successfully uninstalled pandas-1.4.4\n",
            "Successfully installed pandas-1.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons==0.19.0\n",
            "  Downloading tensorflow_addons-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons==0.19.0) (23.0)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons==0.19.0) (6.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons==0.19.0) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow-addons==0.19.0) (3.15.0)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0 typeguard-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VU0wpJkMk1O1"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.layers import Attention\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay, CosineDecayRestarts\n",
        "from keras.callbacks import Callback\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imported Classes"
      ],
      "metadata": {
        "id": "kzYmorFbOby_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine Annealing Scheduler\n",
        "# https://github.com/4uiiurz1/keras-cosine-annealing/blob/master/cosine_annealing.py\n",
        "\n",
        "class CosineAnnealingScheduler(Callback):\n",
        "    \"\"\"Cosine annealing scheduler.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n",
        "        super(CosineAnnealingScheduler, self).__init__()\n",
        "        self.T_max = T_max\n",
        "        self.eta_max = eta_max\n",
        "        self.eta_min = eta_min\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, 'lr'):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "        if self.verbose > 0:\n",
        "            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
        "                  'rate to %s.' % (epoch + 1, lr))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
      ],
      "metadata": {
        "id": "atWNoSB1xERL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LR Finder in Keras\n",
        "# https://github.com/avanwyk/tensorflow-projects/tree/master/lr-finder\n",
        "\n",
        "class LRFinder(Callback):\n",
        "    \"\"\"`Callback` that exponentially adjusts the learning rate after each training batch between `start_lr` and\n",
        "    `end_lr` for a maximum number of batches: `max_step`. The loss and learning rate are recorded at each step allowing\n",
        "    visually finding a good learning rate as per https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html via\n",
        "    the `plot` method.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_lr: float = 1e-7, end_lr: float = 10, max_steps: int = 100, smoothing=0.9):\n",
        "        super(LRFinder, self).__init__()\n",
        "        self.start_lr, self.end_lr = start_lr, end_lr\n",
        "        self.max_steps = max_steps\n",
        "        self.smoothing = smoothing\n",
        "        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n",
        "        self.lrs, self.losses = [], []\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n",
        "        self.lrs, self.losses = [], []\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        self.lr = self.exp_annealing(self.step)\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, self.lr)\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        logs = logs or {}\n",
        "        loss = logs.get('loss')\n",
        "        step = self.step\n",
        "        if loss:\n",
        "            self.avg_loss = self.smoothing * self.avg_loss + (1 - self.smoothing) * loss\n",
        "            smooth_loss = self.avg_loss / (1 - self.smoothing ** (self.step + 1))\n",
        "            self.losses.append(smooth_loss)\n",
        "            self.lrs.append(self.lr)\n",
        "\n",
        "            if step == 0 or loss < self.best_loss:\n",
        "                self.best_loss = loss\n",
        "\n",
        "            if smooth_loss > 4 * self.best_loss or tf.math.is_nan(smooth_loss):\n",
        "                self.model.stop_training = True\n",
        "\n",
        "        if step == self.max_steps:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "        self.step += 1\n",
        "\n",
        "    def exp_annealing(self, step):\n",
        "        return self.start_lr * (self.end_lr / self.start_lr) ** (step * 1. / self.max_steps)\n",
        "\n",
        "    def plot(self):\n",
        "        fig, ax = plt.subplots(1, 1)\n",
        "        ax.set_ylabel('Loss')\n",
        "        ax.set_xlabel('Learning Rate (log scale)')\n",
        "        ax.set_xscale('log')\n",
        "        ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
        "        ax.plot(self.lrs, self.losses)"
      ],
      "metadata": {
        "id": "PQUyj62yLEFQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://gist.github.com/avanwyk/57724eb3cfff60a1451e4b422c73bfb7#file-lr_one_cycle-py\n",
        "import logging\n",
        "\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "class CosineAnnealer:\n",
        "    \n",
        "    def __init__(self, start, end, steps):\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.steps = steps\n",
        "        self.n = 0\n",
        "        \n",
        "    def step(self):\n",
        "        self.n += 1\n",
        "        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n",
        "        return self.end + (self.start - self.end) / 2. * cos\n",
        "\n",
        "\n",
        "class OneCycleScheduler(Callback):\n",
        "    \"\"\" `Callback` that schedules the learning rate on a 1cycle policy as per Leslie Smith's paper(https://arxiv.org/pdf/1803.09820.pdf).\n",
        "    If the model supports a momentum parameter, it will also be adapted by the schedule.\n",
        "    The implementation adopts additional improvements as per the fastai library: https://docs.fast.ai/callbacks.one_cycle.html, where\n",
        "    only two phases are used and the adaptation is done using cosine annealing.\n",
        "    In phase 1 the LR increases from `lr_max / div_factor` to `lr_max` and momentum decreases from `mom_max` to `mom_min`.\n",
        "    In the second phase the LR decreases from `lr_max` to `lr_max / (div_factor * 1e4)` and momemtum from `mom_max` to `mom_min`.\n",
        "    By default the phases are not of equal length, with the phase 1 percentage controlled by the parameter `phase_1_pct`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n",
        "        super(OneCycleScheduler, self).__init__()\n",
        "        lr_min = lr_max / div_factor\n",
        "        final_lr = lr_max / (div_factor * 1e4)\n",
        "        phase_1_steps = steps * phase_1_pct\n",
        "        phase_2_steps = steps - phase_1_steps\n",
        "        \n",
        "        self.phase_1_steps = phase_1_steps\n",
        "        self.phase_2_steps = phase_2_steps\n",
        "        self.phase = 0\n",
        "        self.step = 0\n",
        "        \n",
        "        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n",
        "                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n",
        "        \n",
        "        self.lrs = []\n",
        "        self.moms = []\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.phase = 0\n",
        "        self.step = 0\n",
        "\n",
        "        self.set_lr(self.lr_schedule().start)\n",
        "        self.set_momentum(self.mom_schedule().start)\n",
        "        \n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        self.lrs.append(self.get_lr())\n",
        "        self.moms.append(self.get_momentum())\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        self.step += 1\n",
        "        if self.step >= self.phase_1_steps:\n",
        "            self.phase = 1\n",
        "            \n",
        "        self.set_lr(self.lr_schedule().step())\n",
        "        self.set_momentum(self.mom_schedule().step())\n",
        "        \n",
        "    def get_lr(self):\n",
        "        try:\n",
        "            return tf.keras.backend.get_value(self.model.optimizer.lr)\n",
        "        except AttributeError:\n",
        "            return None\n",
        "        \n",
        "    def get_momentum(self):\n",
        "        try:\n",
        "            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n",
        "        except AttributeError:\n",
        "            return None\n",
        "        \n",
        "    def set_lr(self, lr):\n",
        "        try:\n",
        "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        except AttributeError:\n",
        "            pass # ignore\n",
        "        \n",
        "    def set_momentum(self, mom):\n",
        "        try:\n",
        "            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n",
        "        except AttributeError:\n",
        "            pass # ignore\n",
        "\n",
        "    def lr_schedule(self):\n",
        "        return self.phases[self.phase][0]\n",
        "    \n",
        "    def mom_schedule(self):\n",
        "        return self.phases[self.phase][1]\n",
        "    \n",
        "    def plot(self):\n",
        "        ax = plt.subplot(1, 2, 1)\n",
        "        ax.plot(self.lrs)\n",
        "        ax.set_title('Learning Rate')\n",
        "        ax = plt.subplot(1, 2, 2)\n",
        "        ax.plot(self.moms)\n",
        "        ax.set_title('Momentum')"
      ],
      "metadata": {
        "id": "te4O6z9Zg5-M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Dataset"
      ],
      "metadata": {
        "id": "Tagc4GM2KCxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD1v8irVVL8A",
        "outputId": "b8f007f5-408e-4fec-d7c7-10b23185d1c4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/gdrive/MyDrive/Colab Notebooks/Dataset'\n",
        "fileName = 'csi-dataset-20-7-5.pkl'\n",
        "fullPath = os.path.join(PATH, fileName)\n",
        "print(fullPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5-JT2q-WN6F",
        "outputId": "8c845085-ef55-49ef-e86f-e3fb945e7e4f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/Dataset/csi-dataset-20-7-5.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(fullPath)"
      ],
      "metadata": {
        "id": "qPFc8j7Sl_AE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.sample(frac=1)\n",
        "Y = df['Label'].values\n",
        "X = df['Sample'].values\n",
        "X = [[np.asarray(sample) for sample in i] for i in X]\n",
        "X = np.asarray(X).astype('float32')"
      ],
      "metadata": {
        "id": "9OTolodRQ-6R"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqNzG8VaOtPD",
        "outputId": "9a37039c-6235-4b72-d70a-029b360d332c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6642, 256, 180)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique, counts = np.unique(Y_test, return_counts=True)\n",
        "# print(np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "id": "mpSnjlqxJRGZ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique, counts = np.unique(Y_train, return_counts=True)\n",
        "# print(np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "id": "DOmeeTqDJ0-y"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "vectorized_y = np_utils.to_categorical(encoded_Y)"
      ],
      "metadata": {
        "id": "4nj7Tr5NLTgl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = encoder.classes_\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAFDwJkoAN7s",
        "outputId": "2b140dd5-f9d4-4ec2-fcfc-a5ff89646f5b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I1' 'I11' 'I13' 'I3' 'I5' 'I7' 'I9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,vectorized_y, test_size=0.3, random_state=40)"
      ],
      "metadata": {
        "id": "vZpv6d3uRBgV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],X_train.shape[2],1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],X_test.shape[2],1))\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "Y_train = tf.convert_to_tensor(Y_train)"
      ],
      "metadata": {
        "id": "UibBIJWtRCkL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Model"
      ],
      "metadata": {
        "id": "EmE5iAnfKuK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Components"
      ],
      "metadata": {
        "id": "Z21e1B9_OKf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual Connections\n",
        "# https://stackoverflow.com/questions/64792460/how-to-code-a-residual-block-using-two-layers-of-a-basic-cnn-algorithm-built-wit\n",
        "\n",
        "def resblock(x, kernelsize, filters):\n",
        "    fx = keras.layers.Conv2D(filters, kernelsize, activation='relu', padding='same')(x)\n",
        "    fx = keras.layers.BatchNormalization()(fx)\n",
        "    fx = keras.layers.Conv2D(filters, kernelsize, padding='same')(fx)\n",
        "    out = keras.layers.Add()([x,fx])\n",
        "    out = keras.layers.ReLU()(out)\n",
        "    out = keras.layers.BatchNormalization()(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "5B8Uwo10OfQ6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mish Activation\n",
        "def mish(inputs):\n",
        "    x = tf.nn.softplus(inputs)\n",
        "    x = tf.nn.tanh(x)\n",
        "    x = tf.multiply(x,inputs)\n",
        "    return x"
      ],
      "metadata": {
        "id": "CDOv6JpKRG47"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ranger Optimizer\n",
        "# www.kaggle.com/code/yazanmajzob/ranger-optimizeranvas.com\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def Ranger(sync_period=6,\n",
        "           slow_step_size=0.5,\n",
        "           learning_rate=0.001,\n",
        "           beta_1=0.9,\n",
        "           beta_2=0.999,\n",
        "           epsilon=1e-7,\n",
        "           weight_decay=0.,\n",
        "           amsgrad=False,\n",
        "           sma_threshold=5.0,\n",
        "           total_steps=0,\n",
        "           warmup_proportion=0.1,\n",
        "           min_lr=0.,\n",
        "           name=\"Ranger\"):\n",
        "    inner = tfa.optimizers.RectifiedAdam(learning_rate, beta_1, beta_2, epsilon, weight_decay, amsgrad, sma_threshold, total_steps, warmup_proportion, min_lr, name)\n",
        "    optim = tfa.optimizers.Lookahead(inner, sync_period, slow_step_size, name)\n",
        "    return optim"
      ],
      "metadata": {
        "id": "Kmg26DSAG_J0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building"
      ],
      "metadata": {
        "id": "Au5bnuTWOUnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csiTime_block(input_layer):\n",
        "    # layer_1 = Conv2D(10, (1,1), padding='same', activation='relu')(input_layer)\n",
        "    # layer_1 = Conv2D(16, (10,10), padding='same', activation='relu')(input_layer)\n",
        "    layer_1 = SeparableConv2D(32, (10,10), padding='same', activation='relu')(input_layer)\n",
        "\n",
        "    # layer_2 = Conv2D(10, (1,1), padding='same', activation='relu')(input_layer)\n",
        "    # layer_2 = Conv2D(16, (20,20), padding='same', activation='relu')(input_layer)\n",
        "    layer_2 = SeparableConv2D(32, (20,20), padding='same', activation='relu')(input_layer)\n",
        "\n",
        "    # layer_3 = Conv2D(10, (1,1), padding='same')(input_layer)\n",
        "    # layer_3 = Conv2D(16, (40,40), padding='same', activation='relu')(input_layer)\n",
        "    layer_3 = SeparableConv2D(32, (40,40), padding='same', activation='relu')(input_layer)\n",
        "\n",
        "    layer_4 = keras.layers.MaxPooling2D(pool_size=(1,1))(input_layer)\n",
        "\n",
        "    layer_5 = keras.layers.concatenate([layer_1, layer_2, layer_3, layer_4], axis = 3)\n",
        "\n",
        "    layer_6 = keras.layers.BatchNormalization()(layer_5)\n",
        "    layer_7 = keras.layers.Attention()([layer_6, layer_6])\n",
        "    # layer_4 = SeqSelfAttention(attention_activation='sigmoid')([layer_4, layer_4])\n",
        "    # flatten = keras.layers.Flatten()(attn)\n",
        "    output_layer = keras.layers.Dense(7, activation=mish)(layer_7)\n",
        "    \n",
        "    return output_layer"
      ],
      "metadata": {
        "id": "3HF2Ga72RIXa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.nn_ops import softmax\n",
        "\n",
        "def make_model(input_shape):\n",
        "    input_layer = keras.layers.Input(input_shape, dtype='float32')\n",
        "\n",
        "    fir = csiTime_block(input_layer)\n",
        "    sec = csiTime_block(fir)\n",
        "    res1 = resblock(sec, (3,3), 7)\n",
        "    thi = csiTime_block(res1)\n",
        "    # fou = csiTime_block(thi)\n",
        "    # fif = csiTime_block(fou)\n",
        "    # res2 = resblock(fif, (3,3), 7)\n",
        "    # six = csiTime_block(res2)\n",
        "\n",
        "    gap = keras.layers.GlobalAveragePooling2D()(thi)\n",
        "    dropout = keras.layers.Dropout(.2)(gap)\n",
        "    # layer_4 = keras.layers.Flatten()(layer_4)\n",
        "    output_layer = keras.layers.Dense(7, activation=softmax)(gap) #Need to change to num of classes\n",
        "    \n",
        "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=X_train.shape[1:])\n",
        "# keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "6X8tHx_uRKNW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "AHwM0c7sRNnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd21265b-add4-4733-daa2-0895dc53a07a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 256, 180, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_9 (SeparableC  (None, 256, 180, 32  164        ['input_2[0][0]']                \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_10 (Separable  (None, 256, 180, 32  464        ['input_2[0][0]']                \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_11 (Separable  (None, 256, 180, 32  1664       ['input_2[0][0]']                \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 256, 180, 1)  0          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 180, 97  0           ['separable_conv2d_9[0][0]',     \n",
            "                                )                                 'separable_conv2d_10[0][0]',    \n",
            "                                                                  'separable_conv2d_11[0][0]',    \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 256, 180, 97  388        ['concatenate_3[0][0]']          \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " attention_3 (Attention)        (None, 256, 180, 97  0           ['batch_normalization_5[0][0]',  \n",
            "                                )                                 'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 256, 180, 7)  686         ['attention_3[0][0]']            \n",
            "                                                                                                  \n",
            " separable_conv2d_12 (Separable  (None, 256, 180, 32  956        ['dense_4[0][0]']                \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_13 (Separable  (None, 256, 180, 32  3056       ['dense_4[0][0]']                \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_14 (Separable  (None, 256, 180, 32  11456      ['dense_4[0][0]']                \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 256, 180, 7)  0          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 256, 180, 10  0           ['separable_conv2d_12[0][0]',    \n",
            "                                3)                                'separable_conv2d_13[0][0]',    \n",
            "                                                                  'separable_conv2d_14[0][0]',    \n",
            "                                                                  'max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 256, 180, 10  412        ['concatenate_4[0][0]']          \n",
            " rmalization)                   3)                                                                \n",
            "                                                                                                  \n",
            " attention_4 (Attention)        (None, 256, 180, 10  0           ['batch_normalization_6[0][0]',  \n",
            "                                3)                                'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 256, 180, 7)  728         ['attention_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 180, 7)  448         ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 256, 180, 7)  28         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 180, 7)  448         ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 256, 180, 7)  0           ['dense_5[0][0]',                \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 256, 180, 7)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 256, 180, 7)  28         ['re_lu_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " separable_conv2d_15 (Separable  (None, 256, 180, 32  956        ['batch_normalization_8[0][0]']  \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_16 (Separable  (None, 256, 180, 32  3056       ['batch_normalization_8[0][0]']  \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_17 (Separable  (None, 256, 180, 32  11456      ['batch_normalization_8[0][0]']  \n",
            " Conv2D)                        )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 256, 180, 7)  0          ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 256, 180, 10  0           ['separable_conv2d_15[0][0]',    \n",
            "                                3)                                'separable_conv2d_16[0][0]',    \n",
            "                                                                  'separable_conv2d_17[0][0]',    \n",
            "                                                                  'max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 256, 180, 10  412        ['concatenate_5[0][0]']          \n",
            " rmalization)                   3)                                                                \n",
            "                                                                                                  \n",
            " attention_5 (Attention)        (None, 256, 180, 10  0           ['batch_normalization_9[0][0]',  \n",
            "                                3)                                'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256, 180, 7)  728         ['attention_5[0][0]']            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 7)           0           ['dense_6[0][0]']                \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 7)            56          ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 37,590\n",
            "Trainable params: 36,956\n",
            "Non-trainable params: 634\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 48\n",
        "\n",
        "# lr_finder = LRFinder()\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=100, decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "# lr_schedule = CosineDecayRestarts(initial_learning_rate=0.001,first_decay_steps=100)\n",
        "# lr_schedule = OneCycleScheduler(0.01, 1000)\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"p5.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    # lr_finder\n",
        "    # keras.callbacks.ReduceLROnPlateau(\n",
        "    #     monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
        "    # ),\n",
        "    # CosineAnnealingScheduler(T_max=100, eta_max=1e-2, eta_min=1e-4),\n",
        "    # keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=0, verbose=1),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=Ranger(learning_rate = lr_schedule),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"categorical_accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    # steps_per_epoch = int(trainX_size/batch_size),\n",
        "    # validation_steps = int(trainY_size/batch_size),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "id": "dyDdzsiLRQnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7363ee75-6732-4432-ade2-0abeeea782e8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "78/78 [==============================] - 62s 611ms/step - loss: 0.7675 - categorical_accuracy: 0.6779 - val_loss: 0.7624 - val_categorical_accuracy: 0.6720\n",
            "Epoch 2/20\n",
            "78/78 [==============================] - 47s 605ms/step - loss: 0.7561 - categorical_accuracy: 0.6838 - val_loss: 0.7562 - val_categorical_accuracy: 0.6817\n",
            "Epoch 3/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.7495 - categorical_accuracy: 0.6916 - val_loss: 0.8434 - val_categorical_accuracy: 0.6441\n",
            "Epoch 4/20\n",
            "78/78 [==============================] - 47s 602ms/step - loss: 0.7312 - categorical_accuracy: 0.7023 - val_loss: 0.7695 - val_categorical_accuracy: 0.6989\n",
            "Epoch 5/20\n",
            "78/78 [==============================] - 47s 604ms/step - loss: 0.7289 - categorical_accuracy: 0.6884 - val_loss: 0.7371 - val_categorical_accuracy: 0.6989\n",
            "Epoch 6/20\n",
            "78/78 [==============================] - 47s 605ms/step - loss: 0.7187 - categorical_accuracy: 0.7015 - val_loss: 0.7155 - val_categorical_accuracy: 0.7118\n",
            "Epoch 7/20\n",
            "78/78 [==============================] - 47s 602ms/step - loss: 0.7079 - categorical_accuracy: 0.7053 - val_loss: 0.7569 - val_categorical_accuracy: 0.6720\n",
            "Epoch 8/20\n",
            "78/78 [==============================] - 47s 604ms/step - loss: 0.7069 - categorical_accuracy: 0.7088 - val_loss: 0.7122 - val_categorical_accuracy: 0.6871\n",
            "Epoch 9/20\n",
            "78/78 [==============================] - 47s 602ms/step - loss: 0.6937 - categorical_accuracy: 0.7058 - val_loss: 0.7357 - val_categorical_accuracy: 0.6806\n",
            "Epoch 10/20\n",
            "78/78 [==============================] - 47s 605ms/step - loss: 0.6952 - categorical_accuracy: 0.7155 - val_loss: 0.6906 - val_categorical_accuracy: 0.7086\n",
            "Epoch 11/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.6868 - categorical_accuracy: 0.7147 - val_loss: 0.6949 - val_categorical_accuracy: 0.7108\n",
            "Epoch 12/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.6689 - categorical_accuracy: 0.7249 - val_loss: 0.7031 - val_categorical_accuracy: 0.7065\n",
            "Epoch 13/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.6601 - categorical_accuracy: 0.7330 - val_loss: 0.7412 - val_categorical_accuracy: 0.6946\n",
            "Epoch 14/20\n",
            "78/78 [==============================] - 47s 605ms/step - loss: 0.6548 - categorical_accuracy: 0.7338 - val_loss: 0.6704 - val_categorical_accuracy: 0.7258\n",
            "Epoch 15/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.6421 - categorical_accuracy: 0.7386 - val_loss: 0.6824 - val_categorical_accuracy: 0.7312\n",
            "Epoch 16/20\n",
            "78/78 [==============================] - 47s 605ms/step - loss: 0.6463 - categorical_accuracy: 0.7322 - val_loss: 0.6674 - val_categorical_accuracy: 0.7247\n",
            "Epoch 17/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.6384 - categorical_accuracy: 0.7376 - val_loss: 0.7084 - val_categorical_accuracy: 0.7140\n",
            "Epoch 18/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.6282 - categorical_accuracy: 0.7427 - val_loss: 0.6804 - val_categorical_accuracy: 0.7151\n",
            "Epoch 19/20\n",
            "78/78 [==============================] - 47s 605ms/step - loss: 0.6234 - categorical_accuracy: 0.7394 - val_loss: 0.6603 - val_categorical_accuracy: 0.7344\n",
            "Epoch 20/20\n",
            "78/78 [==============================] - 47s 603ms/step - loss: 0.6034 - categorical_accuracy: 0.7529 - val_loss: 0.7179 - val_categorical_accuracy: 0.6989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "qpTFulowK0eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model(\"sa-mish-adam-150.h5\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test[:,:,:], Y_test)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "metadata": {
        "id": "1RUaJ2nQRUyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1109157c-72dd-4dca-f36a-bd10f2dd7a31"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 8s 119ms/step - loss: 0.6754 - categorical_accuracy: 0.7205\n",
            "Test accuracy 0.7205218076705933\n",
            "Test loss 0.6754424571990967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = \"categorical_accuracy\"\n",
        "plt.figure()\n",
        "plt.plot(history.history[metric])\n",
        "plt.plot(history.history[\"val_\" + metric])\n",
        "plt.title(\"Proposed Model 5's \" + metric)\n",
        "plt.ylabel(metric, fontsize=\"large\")\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "FellN_9WRZzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "f2caf1f0-0ff7-4c27-8cda-be91c9ef8055"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix and Classification Report\n",
        "\n",
        "y_pred=model.predict(X_test) \n",
        "y_pred=np.argmax(y_pred, axis=1)\n",
        "Y_test=np.argmax(Y_test, axis=1)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(Y_test, y_pred, target_names=classes))"
      ],
      "metadata": {
        "id": "Y235RZ51Q4jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86272bdd-8538-43d8-a1bb-efec3e834990"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 8s 117ms/step\n",
            "[[193   5   2   1  25   0   0]\n",
            " [ 17 131   4   0  22  15   0]\n",
            " [  8   2 574   9   7   1  88]\n",
            " [  4   0  12 157   3   8  56]\n",
            " [ 25  30   2   3  82  36   0]\n",
            " [ 16  23   3   1  62  71   0]\n",
            " [  3   0  13  49   1   1 228]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          I1       0.73      0.85      0.78       226\n",
            "         I11       0.69      0.69      0.69       189\n",
            "         I13       0.94      0.83      0.88       689\n",
            "          I3       0.71      0.65      0.68       240\n",
            "          I5       0.41      0.46      0.43       178\n",
            "          I7       0.54      0.40      0.46       176\n",
            "          I9       0.61      0.77      0.68       295\n",
            "\n",
            "    accuracy                           0.72      1993\n",
            "   macro avg       0.66      0.67      0.66      1993\n",
            "weighted avg       0.73      0.72      0.72      1993\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "model.predict(X_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XorlWcV3m9ep",
        "outputId": "9cfa1b92-820e-4b7b-9d53-fd08e249859f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n",
            "CPU times: user 67.8 ms, sys: 4.62 ms, total: 72.4 ms\n",
            "Wall time: 96.5 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.74066250e-04, 3.48512185e-06, 1.35263547e-01, 6.87520653e-02,\n",
              "        4.46116428e-05, 5.40949850e-06, 7.95256793e-01],\n",
              "       [2.82189436e-03, 6.35956079e-02, 1.81027872e-06, 1.00357400e-04,\n",
              "        4.04797882e-01, 5.28540850e-01, 1.41604643e-04],\n",
              "       [1.52976185e-01, 1.62147090e-01, 1.46645971e-03, 2.36842921e-03,\n",
              "        4.10447747e-01, 2.68204659e-01, 2.38941587e-03],\n",
              "       [3.63796055e-02, 8.93095374e-01, 7.47038925e-04, 4.36695962e-04,\n",
              "        3.66294160e-02, 3.25609855e-02, 1.50867520e-04],\n",
              "       [1.74939722e-01, 1.41219512e-01, 2.11012930e-01, 3.78373936e-02,\n",
              "        2.31927037e-01, 1.90685645e-01, 1.23777455e-02],\n",
              "       [1.20237537e-01, 4.60247211e-02, 7.09247828e-01, 1.20069133e-03,\n",
              "        8.16780552e-02, 4.14037518e-02, 2.07439953e-04],\n",
              "       [2.38600709e-02, 1.93261784e-02, 1.21245463e-03, 3.98471504e-01,\n",
              "        1.61255464e-01, 1.44823864e-01, 2.51050442e-01],\n",
              "       [2.05436096e-01, 9.24103614e-03, 1.52622943e-05, 4.39989599e-05,\n",
              "        6.01700902e-01, 1.83401674e-01, 1.61030694e-04],\n",
              "       [6.31770372e-01, 1.05669685e-02, 3.05348933e-01, 3.39626313e-05,\n",
              "        4.42386456e-02, 8.03384837e-03, 7.23202766e-06],\n",
              "       [7.37080455e-01, 7.73139074e-02, 2.33214396e-05, 9.68608560e-07,\n",
              "        1.58107713e-01, 2.74666306e-02, 7.05641878e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}